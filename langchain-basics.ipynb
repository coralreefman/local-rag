{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "`langchain_community`  \n",
    "`langchain-huggingface`  \n",
    "`langchain-openai`  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from a URL  \n",
    "https://python.langchain.com/docs/integrations/document_loaders/web_base/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DocumentLoaders are objects that load in data from a source and return a list of Documents.  \n",
    "A Document is an object with some page_content (str) and metadata (dict).  \n",
    "https://python.langchain.com/docs/how_to/#document-loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import os\n",
    "\n",
    "os.environ['USER_AGENT'] = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a single page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn how to own your home and live anywhere | Home0001HOME0001MenuHOME0001MenuHomes:0001: Lower East SideStudioStudio Max1 Bedr\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://www.home0001.com/how-it-works\")\n",
    "data = loader.load()\n",
    "print(data[0].page_content[:128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legal Notices for 0001 homes live flexibly own your homeHOME0001MenuHOME0001MenuHomes:0001: Lower East SideStudioStudio Max1 Bed\n"
     ]
    }
   ],
   "source": [
    "loader_multiple_pages = WebBaseLoader([\"https://www.home0001.com/how-it-works\", \"https://www.home0001.com/legal\"])\n",
    "docs = loader_multiple_pages.load()\n",
    "print(docs[1].page_content[:128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunk, split and store the data\n",
    "\n",
    "TBD: it's important to figure out the right chunk size later on\n",
    "\n",
    "We use RecursiveCharacterTextSplitter, which will recursively split the document using common separators like new lines until each chunk is the appropriate size.  \n",
    "This is the recommended text splitter for generic text use cases.\n",
    "\n",
    "We set add_start_index=True so that the character index where each split Document starts within the initial Document is preserved as metadata attribute “start_index”.  \n",
    "\n",
    "Next we need to index our text chunks so that we can search over them at runtime. The most common way to do this is to embed the contents of each document split and insert these embeddings into a vector database (or vector store). When we want to search over our splits, we take a text search query, embed it, and perform some sort of “similarity” search to identify the stored splits with the most similar embeddings to our query embedding. The simplest similarity measure is cosine similarity — we measure the cosine of the angle between each pair of embeddings (which are high dimensional vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "990\n",
      "{'source': 'https://www.home0001.com/legal', 'title': 'Legal Notices for 0001 homes live flexibly own your home', 'description': 'Own the perfect home.', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# set up the splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# split the docs\n",
    "splits = text_splitter.split_documents(docs)\n",
    "# create a vector database with the splits\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-large\"),\n",
    "    # persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")\n",
    "\n",
    "print(len(splits))\n",
    "print(len(splits[12].page_content))\n",
    "print(splits[12].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Retriever is an interface that returns relevant Documents from an index based on a string query.  \n",
    "\n",
    "The most common type of Retriever is the VectorStoreRetriever, which uses the similarity search capabilities of a vector store to facilitate retrieval.  \n",
    "Any VectorStore can easily be turned into a Retriever with `VectorStore.as_retriever()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "device to retrieve, index, “scrape,” “data mine” or otherwise gather Site content, or reproduce or circumvent the navigational s\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and generate using the relevant snippets of the site.\n",
    "# retriever = vectorstore.as_retriever()\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "retrieved_docs = retriever.invoke(\"What is home0001?\")\n",
    "\n",
    "print(len(retrieved_docs))\n",
    "print(retrieved_docs[0].page_content[:128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other retrieval techniques include:  \n",
    "- MultiQueryRetriever generates variants of the input question to improve retrieval hit rate.\n",
    "- MultiVectorRetriever instead generates variants of the embeddings, also in order to improve retrieval hit rate.\n",
    "- Maximal marginal relevance selects for relevance and diversity among the retrieved documents to avoid passing in duplicate context.\n",
    "- Documents can be filtered during vector store retrieval using metadata filters, such as with a Self Query Retriever."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio/anaconda3/envs/rag/lib/python3.10/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: filler question \n",
      "Context: filler context \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()\n",
    "\n",
    "# print(example_messages)\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home0001 is a housing collective that offers fully furnished homes for sale, allowing buyers to own their homes outright and participate in a community where they can share and access homes in various locations. Members have the flexibility to make their homes available to others and can swap homes without paying nightly rates. The homes are designed with meticulous attention to detail and come equipped with all necessary furnishings and appliances.Yes, you can rent an apartment through HOME0001. Each home is fully furnished and equipped, making it easy to move in. You also have the option to swap homes with other members in the network.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# print(format_docs(docs))\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "for chunk in rag_chain.stream(\"What is Home0001?\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "print(rag_chain.invoke(\"can i rent an apartment?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "vectorstore.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# website_text = defaultdict(str)\n",
    "\n",
    "# for doc in docs:\n",
    "#     url = doc.metadata[\"source\"]\n",
    "#     website_text[url] += f\"{doc.page_content}\\n\"\n",
    "\n",
    "# print(website_text)\n",
    "# website_text = dict(website_text)\n",
    "# print(website_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008912574, -0.009420217, 0.004011392]\n"
     ]
    }
   ],
   "source": [
    "single_text = documents[1].page_content\n",
    "vector = embed.embed_query(single_text)\n",
    "print(vector[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many more models and providers are available such as Mistral, Ollama, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# vector_store = InMemoryVectorStore.from_documents(docs, OpenAIEmbeddings())\n",
    "\n",
    "# # query = \"is furniture included?\"\n",
    "\n",
    "# results = vector_store.similarity_search(query=\"furniture\", k=5)\n",
    "\n",
    "# for doc in results:\n",
    "#     print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tbd: add local files and more granular examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
