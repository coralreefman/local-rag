{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# Load the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "import json\n",
    "\n",
    "def prepare_qa_documents(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        qa_data = json.load(f)\n",
    "    \n",
    "    documents = [\n",
    "        Document(\n",
    "            page_content=item[\"answer\"],\n",
    "            metadata={\"question\": item[\"question\"]}\n",
    "        )\n",
    "        for item in qa_data\n",
    "    ]\n",
    "    \n",
    "    return documents\n",
    "\n",
    "test_documents = prepare_qa_documents(\"../data/home0001qa.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_qa_texts(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    texts = [f\"Q: {item['question']} A: {item['answer']}\" for item in data]\n",
    "    \n",
    "    return texts\n",
    "\n",
    "test_texts = prepare_qa_texts(\"../data/home0001qa.json\")\n",
    "print(test_texts[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "openai_embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    dimensions=1024  # size of the embeddings you want returned.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "def get_hf_embeddings(model_name):\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name\n",
    "    )\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "mpnet_embeddings = get_hf_embeddings(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "def get_bge_embeddings(model_name, model_kwargs, encode_kwargs):\n",
    "\n",
    "    embeddings = HuggingFaceBgeEmbeddings(\n",
    "        model_name=model_name, \n",
    "        model_kwargs=model_kwargs, \n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "bge_embeddings = get_bge_embeddings(model_name, model_kwargs, encode_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomic\n",
    "https://huggingface.co/nomic-ai/nomic-embed-text-v1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: the text prompt must include a task instruction prefix, instructing the model which task is being performed.  \n",
    "\n",
    "For example, if you are implementing a RAG application, you embed your documents as search_document: <text here> and embed your user queries as search_query: <text here>.  \n",
    "\n",
    "Embed texts as documents:  \n",
    "`documents = ['search_document: TSNE is a dimensionality reduction algorithm created by Laurens van Der Maaten']`  \n",
    "\n",
    "Embed texts as queries:  \n",
    "`queries = ['search_query: Who is Laurens van Der Maaten?']`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nomic-ai/nomic-embed-text-v1.5\"\n",
    "model_kwargs = {'device': 'cuda', 'trust_remote_code':True}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "nomic_embeddings = get_bge_embeddings(\n",
    "    model_name, \n",
    "    model_kwargs, \n",
    "    encode_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "\n",
    "nomic_embeddings_alt = NomicEmbeddings(model='nomic-embed-text-v1.5', inference_mode='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stella\n",
    "https://huggingface.co/dunzhang/stella_en_1.5B_v5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models have multiple dimensions: 512, 768, 1024, 2048, 4096, 6144 and 8192.\n",
    "\n",
    "The higher the dimension, the better the performance. Generally speaking, 1024d is good enough. The MTEB score of 1024d is only 0.001 lower than 8192d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: Queries need one out of two prompts. \"s2p_query\" (e.g. retrieve task) and \"s2s_query\" (e.g. semantic textual similarity task) for sentence-to-passage and sentence-to-sentence tasks, respectively.  \n",
    "Documents don't need prompts.\n",
    "\n",
    "Prompt of s2p task(e.g. retrieve task):\n",
    "\n",
    "`Instruct: Given a web search query, retrieve relevant passages that answer the query.\\nQuery: {query}`  \n",
    "\n",
    "Prompt of s2s task(e.g. semantic textual similarity task):  \n",
    "\n",
    "`Instruct: Retrieve semantically similar text.\\nQuery: {query}`  \n",
    "\n",
    "\n",
    "They are defined in `config_sentence_transformers.json`  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXAMPLE ###\n",
    "query_prompt_name = \"s2p_query\"\n",
    "queries = [\n",
    "    \"What are some ways to reduce stress?\",\n",
    "    \"What are the benefits of drinking green tea?\",\n",
    "]\n",
    "query_embeddings = model.encode(queries, prompt_name=query_prompt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dunzhang/stella_en_1.5B_v5\"\n",
    "model_kwargs = {'device': 'cuda', 'trust_remote_code':True}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "stella_15_embeddings = get_bge_embeddings(\n",
    "    model_name,\n",
    "    model_kwargs, \n",
    "    encode_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dunzhang/stella_en_400M_v5\"\n",
    "model_kwargs = {'device': 'cuda', 'trust_remote_code':True}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "stella_400_embeddings = get_bge_embeddings(\n",
    "    model_name,\n",
    "    model_kwargs, \n",
    "    encode_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "cohere_embeddings = CohereEmbeddings(\n",
    "    model=\"embed-english-v3.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "mistral_embeddings = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "def basic_retriever(documents, embeddings):\n",
    "\n",
    "    # vectorstore = Chroma.from_documents(documents, embeddings)\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = {\n",
    "    \"openai\": openai_embeddings,\n",
    "    \"mpnet\": mpnet_embeddings,\n",
    "    \"bge\": bge_embeddings\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_embeddings.keys())\n",
    "\n",
    "for model in test_embeddings:\n",
    "\n",
    "    vectorstore = FAISS.from_documents(test_documents, test_embeddings[model])\n",
    "    vectorstore.save_local(\"./FAISS\", model)\n",
    "    # retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_retrievers = []\n",
    "\n",
    "for model in test_embeddings:\n",
    "    vectorstore = FAISS.load_local(\n",
    "        folder_path=\"./FAISS\", \n",
    "        embeddings=test_embeddings[model], \n",
    "        index_name=model, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": 4}\n",
    "    )\n",
    "    test_retrievers.append(retriever)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_retrievers[0].invoke(\"what is home0001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_retrievers[1].invoke(\"what is home0001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_retrievers[2].invoke(\"what is home0001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_PROMPT = \"\"\"\n",
    "Expected Response: {expected_response}\n",
    "Actual Response: {actual_response}\n",
    "---\n",
    "(Answer with 'true' or 'false') Does the actual response match the expected response? \n",
    "\"\"\"\n",
    "\n",
    "def test_ticket_to_ride_rules():\n",
    "    assert query_and_validate(\n",
    "        question=\"How many points does the longest continuous train get in Ticket to Ride? (Answer with the number only)\",\n",
    "        expected_response=\"10 points\",\n",
    "    )\n",
    "\n",
    "\n",
    "def query_and_validate(question: str, expected_response: str):\n",
    "    response_text = query_rag(question)\n",
    "    prompt = EVAL_PROMPT.format(\n",
    "        expected_response=expected_response, actual_response=response_text\n",
    "    )\n",
    "\n",
    "    # model = Ollama(model=\"mistral\")\n",
    "    evaluation_results_str = model.invoke(prompt)\n",
    "    evaluation_results_str_cleaned = evaluation_results_str.strip().lower()\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    if \"true\" in evaluation_results_str_cleaned:\n",
    "        # Print response in Green if it is correct.\n",
    "        print(\"\\033[92m\" + f\"Response: {evaluation_results_str_cleaned}\" + \"\\033[0m\")\n",
    "        return True\n",
    "    elif \"false\" in evaluation_results_str_cleaned:\n",
    "        # Print response in Red if it is incorrect.\n",
    "        print(\"\\033[91m\" + f\"Response: {evaluation_results_str_cleaned}\" + \"\\033[0m\")\n",
    "        return False\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid evaluation result. Cannot determine if 'true' or 'false'.\"\n",
    "        )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
